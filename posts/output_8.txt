## Google Ra Mắt PaliGemma 2: Dòng Mô Hình Ngôn Ngữ Thị Giác Mới Siêu Mạnh!

Bạn đã bao giờ tưởng tượng một AI có thể "nhìn" và "hiểu" thế giới xung quanh như con người chưa? Google vừa làm một bước tiến lớn đến gần hơn với giấc mơ đó khi ra mắt PaliGemma 2, một dòng mô hình ngôn ngữ thị giác (vision language model) mã nguồn mở mới, dựa trên nền tảng Gemma 2. Tin vui là nó có nhiều phiên bản với kích thước khác nhau: 3B, 10B và đặc biệt là 28B tham số, đủ mạnh để xử lý các tác vụ phức tạp mà vẫn có thể chạy được trên máy tính cá nhân!

Thông tin này được chia sẻ trên subreddit r/LocalLLaMA, một cộng đồng dành cho những người đam mê các mô hình ngôn ngữ chạy nội bộ (local), và ngay lập tức thu hút sự chú ý. Điều gì khiến PaliGemma 2 trở nên đặc biệt? Và liệu nó có thực sự "ngon" như lời đồn? Hãy cùng khám phá nhé!

Đầu tiên, phải nói đến kích thước 28B. Theo nhiều người dùng, đây là "điểm ngọt" giữa hiệu năng và khả năng chạy trên phần cứng cá nhân. Một thành viên chia sẻ: "Các mô hình 28B (~30B) là lựa chọn yêu thích của tôi. Chúng đủ mạnh mẽ nhưng vẫn có thể chạy khá tốt trên phần cứng cục bộ." Điều này mở ra cánh cửa cho nhiều ứng dụng thực tế hơn, khi mà trước đây, các mô hình ngôn ngữ thị giác thường có kích thước nhỏ hơn (dưới 10B) hoặc quá lớn (như 72B của Qwen VL), khó tiếp cận với người dùng phổ thông.

Vậy PaliGemma 2 có thể làm được những gì? Theo Merve, một thành viên của Hugging Face, PaliGemma 2 là dòng mô hình ngôn ngữ thị giác tốt nhất hiện nay với nhiều phiên bản kích thước và độ phân giải khác nhau (224, 448 và 896) để phù hợp với mọi nhu cầu. Google cũng cung cấp hai checkpoint được tinh chỉnh trên DOCCI, cho khả năng tạo caption chi tiết và sắc thái cho hình ảnh.

Một điểm cộng nữa là PaliGemma 2 được hỗ trợ ngay từ đầu bởi thư viện Transformers, giúp việc tích hợp và sử dụng trở nên dễ dàng hơn. Hugging Face cũng cung cấp các script để tinh chỉnh mô hình cho các tác vụ như trả lời câu hỏi về hình ảnh (VQAv2).

Tuy nhiên, cũng có một số hạn chế. Một số người dùng lo ngại về kích thước cửa sổ ngữ cảnh (context window) của Gemma 2 là 8K, có thể hơi nhỏ cho một số tác vụ. Một số khác thắc mắc về khả năng lập trình của mô hình. Theo một thành viên, PaliGemma 2 "ổn" cho việc lập trình, nhưng điểm mạnh của nó là sự ổn định và khả năng cung cấp thông tin vừa đủ, không quá dài dòng hay ngắn gọn.

Về khả năng chạy trên phần cứng, một người dùng với laptop có card đồ họa 3080ti và 64GB RAM cho biết có thể chạy được mô hình Qwen 32B, với tốc độ "chấp nhận được". Điều này cho thấy tiềm năng của PaliGemma 2 28B trên các cấu hình tương tự.

Một câu hỏi thú vị được đặt ra là liệu PaliGemma 2 có thể phân loại ảnh NSFW (nội dung người lớn) một cách chi tiết hay không. Theo một số ý kiến, có thể cần phải tinh chỉnh mô hình trên một tập dữ liệu phân loại riêng. Tuy nhiên, một số người cho rằng việc này khá lãng phí tài nguyên và có thể sử dụng các mô hình phân loại chuyên biệt hiệu quả hơn.

**Tóm lại,** PaliGemma 2 là một bước tiến đáng chú ý trong lĩnh vực mô hình ngôn ngữ thị giác mã nguồn mở. Với kích thước 28B, nó hứa hẹn mang lại sự cân bằng giữa hiệu năng và khả năng tiếp cận cho người dùng phổ thông. Dù vẫn còn một số hạn chế, nhưng với sự hỗ trợ từ Google và Hugging Face, cùng với cộng đồng đam mê, PaliGemma 2 có tiềm năng mở ra nhiều ứng dụng thú vị trong tương lai.

**Lời khuyên:** Nếu bạn quan tâm đến lĩnh vực này, hãy thử trải nghiệm PaliGemma 2 và khám phá tiềm năng của nó. Đừng quên tham gia các cộng đồng như r/LocalLLaMA để học hỏi và chia sẻ kinh nghiệm. Biết đâu, bạn sẽ là người tạo ra ứng dụng đột phá tiếp theo với PaliGemma 2!


---
Source: https://reddit.com/r/LocalLLaMA/comments/1h7er7u/google_released_paligemma_2_new_open_vision/
