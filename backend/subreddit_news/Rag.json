{
    "items": [
        {
            "title": "Leveraging RAG and AI Agents to transform Customer support efficiency",
            "author": "Cold-Heart-777",
            "text": "[External Link]",
            "subreddit": "Rag",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "**Working on a cool RAG project?**\nSubmit your project or startup to [RAGHut](https://raghut.com) and get it featured in the community's go-to resource for RAG projects, frameworks, and startups.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Rag) if you have any questions or concerns.*"
                },
                {
                    "author": "stonediggity",
                    "text": "Looks pretty cool man well done. Have you thought about using LLM as a router instead of your if/then/else at your second node. Does n8n have that?",
                    "replies": [
                        {
                            "author": "Cold-Heart-777",
                            "text": "Yes :)"
                        }
                    ]
                },
                {
                    "author": "dexterc19",
                    "text": "Hi, very cool! What visualization software are you using?",
                    "replies": [
                        {
                            "author": "stonediggity",
                            "text": "Looks like n8n",
                            "replies": [
                                {
                                    "author": "fredkzk",
                                    "text": "Yes, n8n it is"
                                }
                            ]
                        },
                        {
                            "author": "Cold-Heart-777",
                            "text": "I use n8n"
                        }
                    ]
                },
                {
                    "author": "0xhbam",
                    "text": "That's awesome! Which documents did you use to define the customer support policy in your RAG?",
                    "replies": [
                        {
                            "author": "Cold-Heart-777",
                            "text": "Thank you. I\u2019ve used a fictional one for this exemple (not the real company customer policy)."
                        }
                    ]
                },
                {
                    "author": "Not_your_guy_buddy42",
                    "text": "lol is it for that \"pharmaceutical\" company from The Outer Worlds",
                    "replies": [
                        {
                            "author": "Cold-Heart-777",
                            "text": "Nope. It\u2019s a fictional company I took for the exemple. But the real company is a software company."
                        }
                    ]
                },
                {
                    "author": "SourWhiteSnowBerry",
                    "text": "RemindMe! 1day",
                    "replies": [
                        {
                            "author": "RemindMeBot",
                            "text": "I will be messaging you in 1 day on [**2025-01-25 18:41:04 UTC**](http://www.wolframalpha.com/input/?i=2025-01-25%2018:41:04%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/Rag/comments/1i8ldjk/leveraging_rag_and_ai_agents_to_transform/m8yf7lu/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FRag%2Fcomments%2F1i8ldjk%2Fleveraging_rag_and_ai_agents_to_transform%2Fm8yf7lu%2F%5D%0A%0ARemindMe%21%202025-01-25%2018%3A41%3A04%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201i8ldjk)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|"
                        }
                    ]
                },
                {
                    "author": "Cold-Heart-777",
                    "text": "Just forgot, here is the link to access it : https://ko-fi.com/s/bbbe773a70\nYou\u2019ll also find the file for the AI RAG personal assistant there.",
                    "replies": [
                        {
                            "author": "gtek_engineer66",
                            "text": "For info everybody you have to pay on this website but if you go to n8n you can get the templates for free",
                            "replies": [
                                {
                                    "author": "Cold-Heart-777",
                                    "text": "Not really, because I\u2019ve built it in n8n but not give the template."
                                }
                            ]
                        }
                    ]
                }
            ]
        },
        {
            "title": "Python pdf crawler",
            "author": "Mr_Misserable",
            "text": "Hi, I was wondering if there is a way to define a pdf crawler to downloads PDFs from different websites. Basically I'm looking for a masters, but is a bit time consuming to go to each website navigate until I get to a pdf and try to read the information there, also all the information is not in just un pdf (I just want to know the cost, the GPA requeriments, language requeriments and the due dates to submit stuf, which is the bare minimum all students want to know). \n\nSo basically I want a crawler to download all pdfs to pass it to LLM and create a summary with the information and where it is, to do a quick check.\n\nI tried [Exa](https://exa.ai) but I run out of tokens, and it has no option to download PDFs and the output is not structured in a readable way, is an object and could not manage to transform it to a json so I could at least see just the summary.\n\n  \nThanks for reading",
            "subreddit": "Rag",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "**Working on a cool RAG project?**\nSubmit your project or startup to [RAGHut](https://raghut.com) and get it featured in the community's go-to resource for RAG projects, frameworks, and startups.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Rag) if you have any questions or concerns.*"
                }
            ]
        }
    ]
}