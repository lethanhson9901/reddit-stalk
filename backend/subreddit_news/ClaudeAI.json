{
    "items": [
        {
            "title": "Anthropic CEO says AGI is a marketing term and the next AI milestone will be like a 'country of geniuses in a data center'",
            "author": "MetaKnowing",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "Longjumping_Area_944",
                    "text": "Which isn't a better term. In his essay he called it \"strong AI\". Regardless. The more interesting part of this interview is that he said an AI that can perform all tasks better than all humans is two or three years away.",
                    "replies": [
                        {
                            "author": "Objectionne",
                            "text": "I feel like we're gonna be saying that for the next decade.",
                            "replies": [
                                {
                                    "author": "tennischeeser",
                                    "text": "Lord willing"
                                },
                                {
                                    "author": "sillygoofygooose",
                                    "text": "People in the field have only been saying anything even close to that in the last couple of years"
                                },
                                {
                                    "author": "Dangerous_Bus_6699",
                                    "text": "Why? Have you not seen the commitment companies are pouring into this technology? When the riches people in the world wants to all do the same thing, shits getting real."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Oculicious42",
                    "text": "a country of geniuses with access to all information about every minute detail of our society and technology, who can think for a year in a second, that doesn't sound like n absolute failsafe way to ensure that we are annihilated before we know what hit us",
                    "replies": [
                        {
                            "author": "Equivalent-Bet-8771",
                            "text": "They can't think for a year in a second. They can barely think.",
                            "replies": [
                                {
                                    "author": "Renizance",
                                    "text": "Analyze / predict is the heart of the word \"think\" in that sentence. Genuinely open to hearing your interpretation of that though.\n\n\n\nI agree with you in that saying \"think for a year, in a second\" is way too vague and general to make sense. Maybe if they are referring to simulation training... Sure.\n\n\n\n\n\nSlightly off topic but\n\nFinding novel corelations across many domains of data fast is what LLMs are great at. I think back to the wifi signal data test that used an Ai to predict the environment based on that signal data. Imagine what other corelations between domains we might find with enough data and compute.\n\n\n\nhttps://www.reddit.com/r/AR_MR_XR/comments/1096mm0/full_body_tracking_with_wifi_signals_by_utilizing/?utm_source=share&utm_medium=mweb3x&utm_name=mweb3xcss&utm_term=1&utm_content=share_button"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "AnywhereOk1153",
                    "text": "This is the same thing"
                },
                {
                    "author": "WrexyBalls",
                    "text": "AI won't be smarter than the smartest human that's ever lived for a long time. It's one thing to recall information given, it's a completely different to come up with new ideas and solve problems humans can't.\n\nThe advancement in AI in the short term is the ability to do the complex but sort of repetitive tasks very quickly to test theories. They are still going to be tools.\n\nIt's just a more advanced version of the calculator only for ideas instead of just numbers.",
                    "replies": [
                        {
                            "author": "dreamincolor",
                            "text": "I think you\u2019re going to be proven wrong pretty soon. Let\u2019s come back to this thread in a few years",
                            "replies": [
                                {
                                    "author": "WrexyBalls",
                                    "text": "The drama and hype coming out of these companies aren't based on any real evidence AI is even close to being capable of thinking. It's all just to get people excited. These are structural machines that are programmed to do certain things - thinking isn't one of them and that is what it would take to create a new idea."
                                }
                            ]
                        },
                        {
                            "author": "amphion101",
                            "text": "I think you are wrong. \n\nLLMs are a tool. \n\nThey need frameworks, just like humans do. SOPs, procedures, bureaucracy in a nutshell. \n\nThe baseline is there - no different than the potential of \u201crandom educated human\u201d much like in the colonial age, expected to execute and decide - fork establish decision trees (culture) - just like humans have done. \n\nAs business starts to create frameworks for LLMs to work, this gap will narrow. \n\nBusiness doesn\u2019t understand it yet. \n\nBut they will.\n\nAs those of us who can prove what this technology can do with the right frameworks, let alone instruction. \n\nNo different than onboarding new employees.",
                            "replies": [
                                {
                                    "author": "WrexyBalls",
                                    "text": "that's not the argument, the argument is creating new ideas and actually thinking instead of processing data it's been trained on. that right now is not possible and the blueprint for that is not available otherwise we would know what consciousness is and what it means to be self aware."
                                },
                                {
                                    "author": "amphion101",
                                    "text": "For the record - I am immeasurably excited about this. In ways that I haven\u2019t felt since the introduction of discrete geometry gpus and the internet. \n\nI find it very consequential that the very type of architecture that enables LLMs to work is fundamentally based on the same geometry calculation going back to my first VooDoo2. \n\nThe fact John Carmack is a leader in the field isn\u2019t a coincidence. \n\nIt\u2019s always been about information compression vs render time - that\u2019s a smart human in a nutshell. \n\nHe\u2019s been following that trail of breadcrumbs for 40+ years. \n\nPolygons or next predicted token."
                                }
                            ]
                        },
                        {
                            "author": "distroflow",
                            "text": "> It's just a more advanced version of the calculator only for ideas instead of just numbers.\n\nlisten to yourself",
                            "replies": [
                                {
                                    "author": "WrexyBalls",
                                    "text": "yeah, an idea which humans thought of and put into written words and programmed this computer by defining every fucking letter and then the letters in certain combinations are defined as then sentences in a structure of those letter combinations are defined as and then so on and so on. it's using statistical calculations and pattern recognition from data fed into it. you wouldn't call a k means calculation any sort of intelligence, you wouldn't call any single one calculation intelligence at all but because a string of calculations are programed to mimic something you perceive as general intelligence you consider it to be that and you will dismiss all the things that it can't do because you want to believe it is so. \n\nai can process enormous amounts of data quickly, they don't understand, they don't have consciousness or the ability to reason the way humans do. they don't have that because we don't know how we are able to reason and if we don't know how we are able to reason we can't program ai to reason."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Cagnazzo82",
                    "text": "\"Country of geniuses in a data center\" sounds like a convoluted way of saying AGI.",
                    "replies": [
                        {
                            "author": "ArcEngineAI",
                            "text": "Yes it\u2019s an interesting way to phrase it.. Really what it means is that the notion and expectations of AGI are flawed. \n\nThink about any practical benchmark. With a programmatic tool, an agentic ai can already reach near 100% accuracy. \n\nOf course the scope of the benchmark matters. There\u2019s model property related benchmarks, and practical application related benchmarks. For many of these practical ones, making it an open book test is already more than enough to realize huge enhancements. \n\nYou break a problem space up into specialized task requirements, and then you bring these systems together in an orchestrated framework.  \n\nSuch systems are still in infancy and new research comes out almost every day. But what we do know is that specialized agentic scopes, operating in a hierarchical system, can surpass specific benchmark scores that were designed to test \u201cAGI\u201d. This is where the analogy of \u201ccountries\u201d or \u201ccompanies\u201d comes into play. The orchestration and interaction of specialists, establishing dynamic foundations from the bottom up. \n\nWe see this working really well in cases where the outcome is founded on available data, with  difficulties coming into play at the point of \u201cknowledge inference\u201d, that is LLM reasoning into the truly unknown. \n\nThis is in contrast to the notion of an AGI chatbot that just already knows and can do anything."
                        }
                    ]
                },
                {
                    "author": "ngisab",
                    "text": "ASI - maybe? As it will be superior to our regular creature intelligence."
                },
                {
                    "author": "codywithak",
                    "text": "I fully expect AGI to be achieved just before OpenAI\u2019s IPO."
                },
                {
                    "author": "Peregrine2976",
                    "text": "Actual, genuine, AGI is decades away at *best* (that figure is assuming multiple breakthroughs in developing technologies like quantum computing). Modern attempts are facsimiles. We might see some fairly impressive facsimiles, but still, facsimiles.",
                    "replies": [
                        {
                            "author": "Neuroborous",
                            "text": "You don't need any breakthrough in quantum computing.",
                            "replies": [
                                {
                                    "author": "Peregrine2976",
                                    "text": "We don't need it, no. But it would vastly speed up the process. Without it, I'd say AGI is a century away, absolute minimum."
                                }
                            ]
                        },
                        {
                            "author": "trickyelf",
                            "text": "Define \u201cactual, genuine\u201d",
                            "replies": [
                                {
                                    "author": "Peregrine2976",
                                    "text": "I admit the difference is mostly academic. The end user doesn't care whether the AGI is truly a single unit with broad knowledge and self-agency, or if it's multiple nodes with individual niche specializations all speaking to one another, as long as they can use it like an AGI. It's just my pedantic side being annoyed by the terminology, much like how we refer to modern models as \"AI\"."
                                }
                            ]
                        },
                        {
                            "author": "amphion101",
                            "text": "You aren\u2019t wrong. \n\nThe fault is the assumption humans are not, especially in ways of thinking, just facsimiles.  We all just repeat frameworks we\u2019ve unknowingly or deliberately adopted. \n\nThat means copy and paste. \n\nIf us as facsimile have been this good - imagine a thing that has more present memory and experience infinite speed in processing. Long term context is its weak spot, for sure. \n\nEfficacy is all that matters. Humans have proven this over and over again. \n\nPresent state, elimination of Neanderthals, to simple ability to run more than most other animals. \n\nIt\u2019s all about efficacy."
                        }
                    ]
                },
                {
                    "author": "GeeBee72",
                    "text": "If AGI is a marketing term, then just about everything is. It\u2019s been defined for years as a machine intelligence that can operate in all domains as well as human.  Not better in all domains or better in some domains but garbage in another, it\u2019s being as capable in vision related tasks, math, language, auditory, etc. As a human is"
                },
                {
                    "author": "butthole_nipple",
                    "text": "Dork"
                }
            ]
        },
        {
            "title": "Introducing Citations on the Anthropic API",
            "author": "ZenDragon",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "ZenDragon",
                    "text": "Tl;dr: When you give Claude reference documents and enable this feature, it will hallucinate less when citing information from the source material and return detailed metadata about exactly which parts are being referenced down to the sentence level.",
                    "replies": [
                        {
                            "author": "HeWhoRemaynes",
                            "text": "Holy hell. This is a game changer.",
                            "replies": [
                                {
                                    "author": "SpeedyTurbo",
                                    "text": "It would be a game changer for me if it was on the chat client too\u2026my workflow is already reliant on that because of Projects and the GDocs integration."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "attacketo",
                    "text": "I wonder if it would help with coding also, many diff edits failing, code truncation. It\u2019s not mentioned anywhere, see if Cline picks this up.",
                    "replies": [
                        {
                            "author": "Majinvegito123",
                            "text": "Good point. Thjs would be super beneficial for Cline."
                        }
                    ]
                },
                {
                    "author": "TheseHold6800",
                    "text": "Hey! Does anyone know the token limit for the documents?",
                    "replies": [
                        {
                            "author": "ZenDragon",
                            "text": "If you're sending the document content as plain text then there's no limit as long as the whole request is less than 200K tokens in total. PDF files have to be under 32MB and 100 pages and they eat up 1500-3000 tokens per page on average since they are processed visually and not just as text.",
                            "replies": [
                                {
                                    "author": "TheseHold6800",
                                    "text": "So how is this better than a rag system? Or their contextual retrieval? (Serious question, i have a bunch of reports that are over 100 pages - right now i use openai assistants for the easy to implement RAG) but i dont see how citations is better?"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "thegreatfusilli",
                    "text": "So this works much like NotebookLM?",
                    "replies": [
                        {
                            "author": "ktpr",
                            "text": "NotebookLM doesn't reference the same citation with the same number unfortunately. Making useless for serious work. Claude's implementation is much better already."
                        }
                    ]
                },
                {
                    "author": "coloradical5280",
                    "text": "A lot of talk about API / Web in here so just wanted to mention something I ran across today: \n\n[https://glama.ai/mcp/servers?searchTerm=](https://glama.ai/mcp/servers?searchTerm=)\n\nIt's completely taking out any technical barrier to entry to using MCP.  I personally use MCP in Cline, so, not sure how much I'd use this, but if you're somehow who has stayed away because of complexity, this is the answer, and it also allows you to use everything from mobile as well, which is actually a game changer for MCP stuff."
                },
                {
                    "author": "Fearless_PurpleDog",
                    "text": "As someone who uses Claude as a writing assistant, this is very handy."
                }
            ]
        },
        {
            "title": "So I have been using Professional plan for 2 days now and I get these limits. Isn't itkinda stupid? I pay 22.5 Euros every month to get full experience, only to be limited like free users.",
            "author": "Kajroprakticar",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "When making a complaint, please \n1) make sure you have chosen the correct flair for the Claude environment that you are using: i.e Web interface (FREE), Web interface (PAID), or Claude API. This information helps others understand your particular situation.\n2) try to include as much information as possible (e.g. prompt and output) so that people can understand the source of your complaint.\n3) be aware that even with the same environment and inputs, others might have very different outcomes due to Anthropic's testing regime. \n4) **be sure to thumbs down unsatisfactory Claude output on Claude.ai.** Anthropic representatives tell us they monitor this data regularly.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*"
                },
                {
                    "author": "McNoxey",
                    "text": "How long are your chats? What are you doing? You should keep every single ask to its own chat. Don\u2019t iterate. Preserve memory between questions to carry context over to a new chat. \n\nIf it\u2019s wrong on the first prompt - don\u2019t correct it. Start over. \n\nYou need to manage your costs. Try the api for a week and you\u2019ll realize how absolutely inefficient you\u2019ve been with it. I guarantee you\u2019d blow through your entire 22 euros in 1 day if you were paying for your actual usage",
                    "replies": [
                        {
                            "author": "orangeflyingmonkey_",
                            "text": "How do you carry context to a new chat? I try to keep asks to their own chat but everytime I start a new chat I have to explain what we did before and the next few chats are spent going over and confirming the steps I did in previous chat",
                            "replies": [
                                {
                                    "author": "HelpMeDecideMyName",
                                    "text": "Looking for a good solution to this myself but for now, I ask Claude to summarise the chat with all details necessary and generate a good starting prompt for my next chat with it. I also mention my goals for this next chat. \n\n(I am working on a small-medium Django project at work and am very new to it, so my chats get very long)."
                                },
                                {
                                    "author": "Otherwise_Volume7748",
                                    "text": "The easiest way is to create a project. Whenever an artifact is created add it to project knowledge and then you can refer to it from other chats. Also useful as a tip for using projects, when the chat gets too long ask it create a handover document and save it to project knowledge"
                                },
                                {
                                    "author": "McNoxey",
                                    "text": "I format my prompts in XML blocks and reference the blocks in my <user-prompt> block. \n\nGenerate or squire whatever context you need then feed it back in that style. \n\nYou can use the MemoryMCP to do a similar thing, but it\u2019s not explicit."
                                },
                                {
                                    "author": "Similar-Plan-9643",
                                    "text": "Use MCP. No need to copy and paste. Also, you can edit the message you sent and get a new response if you didn't like the response, instead of using more tokens."
                                },
                                {
                                    "author": "Efficient_Ad_4162",
                                    "text": "Rather than thinking too hard about carrying chats over, you should try to break your task into smaller chunks and learn where to draw a line in the sand. With coding, I have it design small discrete modules with fixed interfaces and then integrate them manually. Each module is its own chat that doesn't need to know about the others."
                                }
                            ]
                        },
                        {
                            "author": "dr_canconfirm",
                            "text": "See how ridiculous it is when you articulate it out loud like that? How frugal and miserly you have to be just to get bare minimum utility out of a $20 plan? While Anthropic forces you to count every token and scrap with response length settings, Google Chads are out there doing 5000 prompts a day with 4 million tokens each\u2013for FREE. The data Anthropic's generating is worth enough as is, they know they're gonna own the world anyway. They're just double dipping! Enshittification is here early.",
                            "replies": [
                                {
                                    "author": "RenoHadreas",
                                    "text": "I agree with you that the limits are ridiculous but I\u2019d like to point out that Anthropic doesn\u2019t train on your outputs unless you use the thumbs up/down button or your chat gets flagged"
                                }
                            ]
                        },
                        {
                            "author": "Pm2r_bis",
                            "text": "Can you give some hints to avoid waste money with bad API usage ?",
                            "replies": [
                                {
                                    "author": "Aggravating-Neat-213",
                                    "text": "If you are working with long code, enter as a statement that only changes should be specified in the artifacts. As an additional instruction, you must specify that it should describe exactly where to make the change, otherwise you will never find a place if you don't know the code 100 percent. That alone got me a few hours further. \n\nWrite your prompts in a text editor. \n\nDon't talk like a human with the ai with all the flowery words. It's hard when you're a polite person, but the ai can't do much with it. \n\nOnce I got the hang of it, it went better and better."
                                },
                                {
                                    "author": "McNoxey",
                                    "text": "Manage your context yourself. Don\u2019t iterate on chats. Define your prompts effectively with clear sections directions and variables. \n\nPlan your work. Plan. Plan.\n\nConsider that even when using the best ai coding agents, at the end of the day it comes down to one prompt. All of the magic is just context gathering to enhance the prompt that \u201cdoes the thing\u201d \n\nIf you can gather and supply the context and direction upfront, your costs go down. \n\nIf you code, use aider. It\u2019s much more manual, but it teaches you how to manage prompts, context and models. \n\nThose are the 3 pillars"
                                }
                            ]
                        },
                        {
                            "author": "ReasonablePossum_",
                            "text": "Yeah, I was shocked when after certain number of messages you get to ridiculously high costs of like 2$ per reply lol",
                            "replies": [
                                {
                                    "author": "big-blue",
                                    "text": "On OpenRouter I've used like $0.50 in three weeks. Rather infrequent usage and recently switched to DeepSeek R1, but I wasn't aware how big of a difference this actually made until I tried it.\n\nKeep your chats reasonably short. Think before you prompt. It works."
                                },
                                {
                                    "author": "McNoxey",
                                    "text": "You just need to remember that the entire history of everything you\u2019ve asked and everything it\u2019s provided is carrying through each response. \n\nIf you looked at the actual prompt that\u2019s sent to the LLM for your final message and started at that point you\u2019d have a much lower total cost. \n\nAll of the back and forth is simply preparing context"
                                }
                            ]
                        },
                        {
                            "author": "Suspicious_Hunt9951",
                            "text": "nice way to say if you want anything complex just don't lol",
                            "replies": [
                                {
                                    "author": "McNoxey",
                                    "text": "That\u2019s not what I\u2019m saying in any way whatsoever. \n\nYou can do more complex things with this workflow because your context is much more specific to the ask."
                                }
                            ]
                        },
                        {
                            "author": "Specific_Tomorrow_10",
                            "text": "While these are all fair points, the usage is definitely inefficient and a real limiting factor. I can work on a complex problem for 10 to 15 minutes at most and I already do everything you are saying. In fact, Claude's own attempts to manage output limits often lead to wasted time and breaking the limits faster. Having to tell the model not to give vague bullets only for it to apologize multiple times and then give the input it is capable of is just wasting its infra and our time.\n\nStill great and I use it everyday, but I think it's worth noting these issues aren't just user error, as some like to respond...",
                            "replies": [
                                {
                                    "author": "McNoxey",
                                    "text": "Don\u2019t tell it. Use better prompts. Your prompt or provided context should be handling that. You should be specifying the output you want. If you want to get the most out of these models you need to give them very good direction."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Kwatakye",
                    "text": "Thats wild because I've hit the limit maybe twice in the last 4 months and I've got several hundred chats and almost a dozen projects. \n\nOne thing that might help you is this: heed the warning when they say long chats increase your usage and make you hit limits quicker.\n\nWhen I get that message, I know the chat is getting too long in tooth and start telling Claude to summarize the discussion into a detailed report or cheat sheet. I'll then upload that report in a new chat and start the conversation back up. I never go more than 2 prompt inputs after that warning message unless I feel like i can wrap up the conversation adequately in 3 or 4 more prompts\n\nOnly problem with this method is sometimes the warnings aren't consistent. I'll open a chat on the phone and see the warning there that wasn't on the desktop or vice versa. Regardless, I close the convo out, and start it up again in a new chat.\n\nWAAAAAAAY better experience that ChatGPT Pro when I got network warnings on the first message of the day after not even using it the day before. Endured exactly 1 month of that \\*uckery and said NOPE, let's try Anthropic."
                },
                {
                    "author": "DigbyGibbers",
                    "text": ">\u00a0I think I should get unlimited messages. After all I dont want to pay that amount of money for limitations.\n\nThey are quite clear about the limits. If you don't want to pay for it then don't or you can use the API and pay as you go.",
                    "replies": [
                        {
                            "author": "Timely-Group5649",
                            "text": "Quite vague, you mean.\n\nWe get 5 times something...",
                            "replies": [
                                {
                                    "author": "LotusTileMaster",
                                    "text": "People love to defend the actions of corporations as just when they disclose that they will give you 5x more than Bob and Alice use. \n\nHow much do Bob and Alice use? Well, 5x less than you, obviously!"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Professional-Fuel625",
                    "text": "It's weird that everyone here argues against themselves. Apathy like this is why billionaire capitalists win.\n\nYeah they have to pay for compute, but the pro tier limits are pretty low, and using the API is more annoying and risk of overspending without noticing.",
                    "replies": [
                        {
                            "author": "Alcoding",
                            "text": "They don't argue against themselves. They argue for fairness. As long as there's competition in the market, if you don't like the limits, go and find a different company that has higher limits.\n\nSure everyone can say yeh it should be limitless, but it's disingenuous and not financially viable for businesses to offer that",
                            "replies": [
                                {
                                    "author": "Professional-Fuel625",
                                    "text": "You should always ask companies for more, not just say \"ok\" and give in. Corporations will *always* ask you for more and give you less (including safety).\n\nAnd fwiw I pay $200 for chatGPT pro. The reasoning for Claude is better for some tasks, but the far greater output window for code (it seems to be literally 20-50x the size?) of chatGPT is what makes it worth that.\n\nI would definitely not pay $200/mo for Claude, but the limits for $20/mo seem too low."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "WhiteRabbit-Pill",
                    "text": "Why not use deepseek?"
                },
                {
                    "author": "Potential-Devv-259",
                    "text": "Just use deepseek lol, much more powerful+ it's free"
                },
                {
                    "author": "Timlead_2026",
                    "text": "Yes, limits are reached very quickly with Claude Pro !"
                },
                {
                    "author": "Varoo_",
                    "text": "use t3 chat, it is sonnet cheaper and ulimited lol",
                    "replies": [
                        {
                            "author": "CompetitivePin7227",
                            "text": "Hoody AI is a bit cheaper, 100 messages a day\\~ with Sonnet 3.5 for 65 bucks a year.",
                            "replies": [
                                {
                                    "author": "IllVeterinarian4200",
                                    "text": "also most of other models & many more features available for 65$/year  \ngreat deal, probably won't last much longer\n\n(been using Hoody instead of Claude Pro for 2 months now)"
                                }
                            ]
                        },
                        {
                            "author": "Kindly_Manager7556",
                            "text": "it's not unlimited, lol"
                        },
                        {
                            "author": "ComputerMinister",
                            "text": "500 messages a week* (pro plan)",
                            "replies": [
                                {
                                    "author": "Varoo_",
                                    "text": "oh didn't know, when they started they said it was unlimited.\n\nThat's a good rate tho."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Remicaster1",
                    "text": "Hi, let me help you out a bit\n\nThe reason why subbing for Claude.ai (we call it web ui) has a limitation is because computing is not free. This same applies to ChatGPT Plus with their o1 model, same as GPT-4 and GPT-4o. None of them are truly unlimited for high compute AI models. Even ChatGPT Pro with unlimited o1 pro usage, OpenAI is actively losing money with this business model and it cost 200$\n\nYou can either stick with web ui or use their API for a pay-as-you-go usage plan. Here is a guide for this\nhttps://www.reddit.com/r/ClaudeAI/s/nTnj7U3rj1\n\nIf you want to stick with this web ui, consider using smaller chat windows, keep starting new chats whenever the context is not needed, and avoid using large project that uses more than 20% of context size. This allow you to opt for more usage as Claude takes total tokens consumed rather than messages sent. The longer your chat contents the faster you'll hit limits\n\nLemme know if u need help",
                    "replies": [
                        {
                            "author": "Kajroprakticar",
                            "text": "That is a good advice. Thank you. But like you said, it is expensive (I dont know how to reply to certain sentences of comment). That is why I am paying. I just feel like a loser for paying 22 euros for something I cannot use fully. Free version I understand. But paying that amount of money and not get full service feels like a scam. I know I wont be continuing the subscription, thats for sure.",
                            "replies": [
                                {
                                    "author": "McNoxey",
                                    "text": "I really encourage you to reproach the tool vs giving up. It feels like a scam to you because you don\u2019t actually understand what you\u2019re doing. \n\nHow many chats are you normally on before you hit your limit? How many individual chat sessions, I mean."
                                },
                                {
                                    "author": "Remicaster1",
                                    "text": "to give you more understanding on why a limit is imposed. There is a similar AI tool that is \"open sourced\", anyone can use it. It is called Llama AI, by Meta (facebook) and Microsoft.\n\nTheir flagship model at that time was The Llama 3.1 405b model (just think of a very large model) that is nowhere, not even close to the intelligent that Claude 3.5 Sonnet has. But it has similar performance to the old GPT-4 from OpenAI.\n\nThe best consumer graphic card you can get on the market is the Nvidia 4090 at that time, (5K series only released very recently), people having the best graphics card at the time, could not even run the model. It can't even generate any text with it. Some guy on the reddit has [tried to self host ](https://www.reddit.com/r/LocalLLaMA/comments/1ej9uzh/local_llama_31_405b_setup/)the 405b, and it honestly looked crazy, and it is just for 1 person. Imagine now you have more than a million active users using your platform. Think how much that cost you, just the electricity fee for all the infrastructure, ignore the investment itself alone.\n\nSo honestly I can't really think of this as a scam, the limit imposed is just a limitation on the current state of the AI. And honestly, based on your current usage, you are likely going to spend more than 100$ a month on the API cost, and I think this 20$ is the best deal you can get, given that this is one of the best AI model you can get out here. From my experience, nothing stands close, even Deepseek R1 which a lot of benchmark stats it rivals Sonnet 3.5\n\nEDIT: [https://www.reddit.com/r/ClaudeAI/comments/1hxrpzm/what\\_would\\_you\\_like\\_to\\_see\\_addedfixed\\_in\\_claudeai/](https://www.reddit.com/r/ClaudeAI/comments/1hxrpzm/what_would_you_like_to_see_addedfixed_in_claudeai/) pin comment, the CEO already knew this issue, but i also understand that this problem is not an overnight fix, it takes a lot of time and effort for it"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Synth_Sapiens",
                    "text": "No. You don't. And you shan't."
                },
                {
                    "author": "Laser-Brain-Delusion",
                    "text": "You could always sign up for a team account and pay $150 a month to have more or less unlimited access for your team."
                },
                {
                    "author": "victorantos2",
                    "text": "[Sneos.com](http://Sneos.com) is also cheaper at the moment, I mean free for now"
                },
                {
                    "author": "heythisischris",
                    "text": "Try using Colada for Claude, it's a Chrome extension which helps you get past your daily limits using your own Anthropic API key: https://usecolada.com"
                },
                {
                    "author": "Blade2075",
                    "text": "The limits are annoying but I have two accounts with Pro subscriptions. When I hit the limit on one it asks to return back in 4 hours as an example. So I use my 2nd account and I usually get 3-4 hours of work out of it. Like this I can cycle through the entire day without being bothered by limits. I just copy and paste the conversations over if I want to continue.\n\nI mainly deal with programming tasks so I'm always starting new chats anyway.\n\nI may be paying more but it's much better and cheaper than the 200 dollar ChatGPT Pro subscription."
                },
                {
                    "author": "Aggravating-Neat-213",
                    "text": "Remembering my first first days with Claude, came from chatgpt and was totally struggling. With practice, you'll learn this quickly."
                },
                {
                    "author": "joelrog",
                    "text": "Every flagship LLM has limits even for paid users\u2026 not sure why $20/month should get you infinite use. It\u2019s a resource that costs money and they have to limit or there\u2019d be no profitability."
                },
                {
                    "author": "YungBoiSocrates",
                    "text": "1) Turn off artifacts (this is most important)\n\n2) Turn off everything actually. Any features/settings should be switched off.\n\n3) If you put in a ton of tokens (text), only ask what you need from that. Then start a new convo. Continuing with the same convo when you have a giant amount of tokens will rapidly diminish your limit.\n\nThat's all there is to it"
                },
                {
                    "author": "nostraticispeak",
                    "text": "I never quite understood the \"You may be able to continue with Haiku\" suggestion. Can I continue this conversation in Haiku? Start a new one with Haiku and lose the current context? It is the latter but implies the former."
                },
                {
                    "author": "surfmaths",
                    "text": "Unfortunately, large frontier LLMs are estimated to cost, in average, 200$/month per users, and that's only counting paying users. API users tend to be unbounded in how much they use it. \n\nBut the problem is nobody is willing to pay 200$/month. So there are a few alternatives: switch heavy users to the cheaper model once they reach a limit, rely on investors cash flow to pay the difference, make a price per token, provide a 200$/month subscription. \n\nPick your poison, but that's the current state of Frontier LLM. ChatGPT is sucking their investors money, so in terms of quality vs price they are likely the best.\n\nAlso, don't hesitate to try out locally run LLMs, like llama, qwen or more recently deepseek."
                },
                {
                    "author": "OliviaAnonymous",
                    "text": "I agree."
                },
                {
                    "author": "jblackwb",
                    "text": "Maybe you'd be happier using the API and paying as you go?"
                },
                {
                    "author": "excelsior888",
                    "text": "Right? I've stopped using Claude directly because of that. The limit is too low."
                },
                {
                    "author": "taiwbi",
                    "text": "Free users just completely lost access to sonnet about 48 hours ago, and it's still on Haiku"
                },
                {
                    "author": "topcomets",
                    "text": "Same, I\u2019m asking tiny questions and it fails halfway thru.. unusable .. and this is the first day I\u2019ve used it all month."
                },
                {
                    "author": "FadiTheChadi",
                    "text": "Laughs in API"
                },
                {
                    "author": "No_Indication4035",
                    "text": "why don't you use the API"
                },
                {
                    "author": "Efficient_Love_479",
                    "text": "Look, if limits are a big problem for your use case- this is probably not the right solution. If you\u2019re dealing with big files or lots of data there are cost optimized systems that will help you out.\n\nSpecific systems excel in specific cases. You just gotta find the right one for your workflow, or sacrifice cost efficiency which isn\u2019t really viable for a fixed subscription model, hence the limits. \n\nOf course they are throttled more at times, but if this is a very common issue you should move to another tool. For example, in many data rich cases RAG based memory is much more effective, on the other hand for less rich cases full context can yield more comprehensive output. \n\nMaybe i\u2019m wrong but I view claude.ai as more of a showcase, they don\u2019t cost optimize so that they get the best possible quality, but of course this hits a wall at $20/month. This is part of the reason that Claude powered products like perplexity or copilot feel so different from claude.ai- because they\u2019re heavily optimized for a use case."
                },
                {
                    "author": "sammoga123",
                    "text": "Better to pay for the API or a third-party service, Claude's official platform and its limits are laughable",
                    "replies": [
                        {
                            "author": "TheArchivist314",
                            "text": "wrong better to save your money build a machine to run your stuff local and have an even a lower cost and no limits"
                        }
                    ]
                },
                {
                    "author": "theflippedbit",
                    "text": "lost you at \"unlimited messages\"."
                },
                {
                    "author": "Track6076",
                    "text": "Those damn free users \ud83d\udc80 using up our tokens, wasting our tax money on the poor, they need to pull their weight \ud83d\ude02"
                },
                {
                    "author": "Brustty",
                    "text": "And it keeps asking if you want to continue just to waste credits. Claude fell off hard. I can't even get it to write a normal email or format things anymore."
                },
                {
                    "author": "buenology",
                    "text": "I cancelled my subscription, pretty disappointed."
                },
                {
                    "author": "datacog",
                    "text": "OP - If you're looking to have a dedicated coding experience, you really need to use a different tool which allows you to use Claude sonnet. There are several, you could try Poe, however I think you can give [Bind AI](https://app.getbind.co/chat/bind-ai?model=advanced) a try (no interruptions, 3M tokens and get unlimited usage with your API key). I am affiliated with Bind, so take this with a pinch of salt. You could also try cursor or windsurf, which are great, but not general purpose chat."
                },
                {
                    "author": "Crypticrichie",
                    "text": "Welcome to the club"
                },
                {
                    "author": "unfoxable",
                    "text": "What\u2019s with people thinking they\u2019re entitled to unlimited usage for $20? Madness, especially when they tell you that you get 5x more than free users before you click purchase",
                    "replies": [
                        {
                            "author": "MrTooMuchSleep",
                            "text": "And how much does a free user get?.. it should be quantified and then it is easier to forgive or adjust"
                        }
                    ]
                },
                {
                    "author": "stormthulu",
                    "text": "I only get those limits when I\u2019m pouring massive amounts of text through the system. So you\u2019re doing something that is pushing massive amounts of context, or asking Claude to do massive amounts of output, in a short period of time."
                },
                {
                    "author": "upandfastLFGG",
                    "text": "I use it everyday. There\u2019s no comparison between the pro plan and free version in terms of rate limit. \n\nI haven\u2019t had any issues with rate limiting on the pro plan. I just follow the suggestion of periodically starting a new chat"
                },
                {
                    "author": "Street-Pea8730",
                    "text": "cancel your sub. This company doesn't care about you or your limitations. Strongly suggest using Oai (for general use) or Gemini advanced (for coding)",
                    "replies": [
                        {
                            "author": "Next_Instruction_528",
                            "text": "All I have seen from this sub is complaints about cost and restrictions while every one else is getting cheaper and better. He isn't wrong."
                        }
                    ]
                },
                {
                    "author": "Ilovesumsum",
                    "text": "Cry me a river.",
                    "replies": [
                        {
                            "author": "Dramatic-Fox-8395",
                            "text": "Black muddy river"
                        }
                    ]
                },
                {
                    "author": "vamonosgeek",
                    "text": "The issue is using the chat for developer questions that may include code snippets or longer code pieces from sonnet is what makes the chat get longer and that\u2019s when the limit is reached fast. \n\nClaude.ai is made to use with simple chats. Simple sentences. Helping you \u201cwhen needed\u201d.  \n\nIf you are a developer, then you go to cursor.com and pay for that instead of the chat."
                },
                {
                    "author": "Funny_Ad_3472",
                    "text": "You can use [Enjoy Claude](https://workspace.google.com/marketplace/app/enjoy_claude/878917104949) through the API, it gives a similar UI as the Claude interface. It is better to use free Claude and use the API as supplementary when you're limited."
                },
                {
                    "author": "Outside-Pen5158",
                    "text": "it's truly a testament to Claude's egalitarian nature. it doesn't see free or Pro, it sees only limits"
                },
                {
                    "author": "Outside-Pen5158",
                    "text": "it's truly a testament to Claude's egalitarian nature. it doesn't see free or Pro, it sees only limits"
                }
            ]
        },
        {
            "title": "Posts related to rate limits shouldn't be allowed.",
            "author": "Sezarsalad70",
            "text": "This subreddit works best when we share real news about Claude, cool projects people make, and how Claude compares to other AI. We absolutely don't need more posts about hitting message limits - especially when Claude already warns you about this.\n\nI'm calling out to the mods, please do something about this. The spam is getting outrageous.",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "Warm_Data_168",
                    "text": "If this many people are bothered by it then it means it is a real problem and not \"spam\". It means that most people are upset about it and because of this if Claude does not hear about it then it would harm their bottom line in the end to not be pressured by the large amount of feedback about this serious problem.",
                    "replies": [
                        {
                            "author": "animealt46",
                            "text": "Everyone knows it\u2019s a problem. There\u2019s nothing to discuss on this subreddit if the same thread on limits and defending or criticizing it is all that is going to happen."
                        }
                    ]
                },
                {
                    "author": "danielbearh",
                    "text": "I agree. Its a valid concern, but one we are all painfully aware of.\n\nIndividuals are getting frustrated and turning to the subreddit for the first time, I assume. Otherwise there\u2019s no way in hell they\u2019d want to contribute to the 15 of these a week."
                },
                {
                    "author": "Skyoddity",
                    "text": "Be the change you want to see in the world.",
                    "replies": [
                        {
                            "author": "Next_Instruction_528",
                            "text": "As someone who's never used it in an outsider. Looking in on this subreddit. I feel like the only time I ever see a post from this subreddit is complaining about rate limits. I didn't know you guys made other posts"
                        },
                        {
                            "author": "ThaisaGuilford",
                            "text": "I still don't understand the rate limiting"
                        }
                    ]
                },
                {
                    "author": "deadshot465",
                    "text": "The problem is Claude never claims providing unlimited usage when you subscribe to it. Most people who complained clearly didn't even read before clicking the subscribe button."
                },
                {
                    "author": "AnywhereOk1153",
                    "text": "I disagree, rate limits are a legitimate user concern. Posts about them can serve to educate the poster on how to optimize rate limit or educate others on what not to do.",
                    "replies": [
                        {
                            "author": "Efficient_Ad_4162",
                            "text": "A megathread would be nice though."
                        },
                        {
                            "author": "dabadeedee",
                            "text": "Yeah but how many threads do you believe we need about it??\n\nRemember it isn\u2019t Anthropic reading this shit, its regular ppl like me and im tired of the senseless complaint posts as if this is some kind of customer support / emotional support \u00a0forum"
                        }
                    ]
                },
                {
                    "author": "Robonglious",
                    "text": "If there weren't posts about rate limits, would there be any posts?"
                },
                {
                    "author": "urbanevol",
                    "text": "I would encourage the mods to make a weekly complaint thread and remove any low-effort posts about message limits.",
                    "replies": [
                        {
                            "author": "Briskfall",
                            "text": "I ranted in plenty of my comments about that and mailed them and told them a while ago (1-2 months) and they're... well, kinda firm(?) on their position.\n\nMaybe they'll need more persuasion with more people mailing them?"
                        },
                        {
                            "author": "Thinklikeachef",
                            "text": "That seems like a good compromise."
                        },
                        {
                            "author": "Sezarsalad70",
                            "text": "Great idea!"
                        },
                        {
                            "author": "dabadeedee",
                            "text": "Mods on all AI subreddits pretty much blow\n\nMy favourite subs are ones with GOOD moderation vs free for alls. Because free for alls end up rewarding useless spam. It always has happened on Reddit and always will.\u00a0\n\nThe thing that gets the upvotes is the one that takes the least time to digest and appeals to the largest, dumbest contingent\u00a0"
                        }
                    ]
                },
                {
                    "author": "calgeorge",
                    "text": "And am I the only who's never noticed it? I'll sit messaging in the same session for hours and never hit the limit, even with multiple large attachments. What are some of y'all doing?",
                    "replies": [
                        {
                            "author": "celtic_cuchulainn",
                            "text": "Same or when I hit my limit, it usually renews in an hour or so, which is reasonable and gives me an excuse to take a break. I\u2019m operating with about 50% full project knowledge folder.\n\nThe common pitfall seems to be not wanting to start a new chat so you can keep the context. I sometimes ask Claude to create a quick reference summary document of the chat, upload, then continue the conversation in a new chat.",
                            "replies": [
                                {
                                    "author": "Head-Cup-9133",
                                    "text": "I thinks it\u2019s the non technical people that think they can build the next facebook in one day with one chat. The people that hit these limits don\u2019t have enough context themselves to break into other chats."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Mr-Barack-Obama",
                    "text": "Rate issues are important and relevant to talk about, especially in the future with different models that may come out. You don\u2019t have to love every post on this subreddit and that fine. A year from now with a new Claude model you might even want to talk about something related to its rate limit, but no, it\u2019ll be banned."
                },
                {
                    "author": "EYNLLIB",
                    "text": "There needs to be a megathread for those types of posts, it's not what people come to this sub to see and shouldn't be the purpose of this sub"
                },
                {
                    "author": "Apprehensive-Ant7955",
                    "text": "these top AI companies are in these subreddits, complaining about things you want changed is a good thing"
                },
                {
                    "author": "Funny_Ad_3472",
                    "text": "Please let people be and let them poor out their frustration. If they want to complain about rate limits all day, let them be. There are new people joining this subreddit everyday. When they complain, they may get suggestions how to go about it. Some people do not even know how to generate an API key. And most of the platforms for using the API are so technical to set up. Not everyone is a developer. I've developed so many software, but I've never used an IDE before. Let people be!",
                    "replies": [
                        {
                            "author": "Sezarsalad70",
                            "text": "There can be a pinned thread that answers the most common questions these people have, that helps them generate keys and solve their frustrations. But using the whole subreddit for this issue frustrates many people. We can find a middle ground where everyone is happy.",
                            "replies": [
                                {
                                    "author": "dabadeedee",
                                    "text": "For some reason certain people hate moderation and pinned posts despite them working extremely well\n\nIMO mods are just lazy\u00a0"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Old_Taste_2669",
                    "text": "i can't reply at the moment as i'm out of messages until 9pm but I'll see you then, unless you're a Haiku kinda guy."
                },
                {
                    "author": "Timely-Group5649",
                    "text": "Isn't this a post about rate limits?",
                    "replies": [
                        {
                            "author": "l0033z",
                            "text": "It\u2019s asking us to rate limit posts about rate limiting",
                            "replies": [
                                {
                                    "author": "Timely-Group5649",
                                    "text": "So, we could either ratify rating rate limit posting or rate him down for rate limit post ranting."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "antkn33",
                    "text": "It would help if Claude was more transparent and straightforward about it."
                },
                {
                    "author": "adyrcz",
                    "text": "This is exactly what brought me to the subreddit today."
                },
                {
                    "author": "TheStuntToddler",
                    "text": "You might as well just say hide the complaints because they\u2019re unsightly. \n\nAnd for the record, Claude will remind you at the very inopportune moments that is approaching the limit just before it does. And when you\u2019re knee deep into the thing,  that could be painful.\n\nThankfully, projects help get passed a lot of this, but not enough. \n\nHow about if we also not allow posts that let conscientiousness and don\u2019t really take the bigger picture of the user base. Or maybe we could do some more offhand disallowance of other posts that people find unsightly. Maybe posts about: coding, or or writing, or any complaint any complaint at all.  \n\nJust make everything fresh and rosy. \n\nBut I\u2019d love to hear your other well thought out plans too. Cause I wanna make sure you\u2019re heard even though you wanna make sure others aren\u2019t.\n\nFigure it out, man."
                },
                {
                    "author": "MossyMarsRock",
                    "text": "Agreed. A dedicated thread for rate complaints would be nice. \n\nif it's that upsetting, canceling one's subscription isn't hard."
                },
                {
                    "author": "diphthing",
                    "text": "I\u2019m a bit of a lurker and was mainly looking for advice and ideas. The rate-limit posts are really just noise, in that I\u2019m well aware of the rate-limits. I, like most everyone else here, just adjust to them and use Claude to help with various tasks within those limits (in my case, mainly coding.) More content about setups, projects, tools (like MCPs) and workflows were more what I was hoping for. Instead this sub is a lot of low effort complaining. So yes, I would very much support limiting rate-limit complaints to a single thread I can avoid, or just ban those altogether. It\u2019d be a much better sub."
                },
                {
                    "author": "Independent_Roof9997",
                    "text": "I'm using Claude until there's a better alternative, for now I still believe sonnet 3.5 is the best one out there for me. I'm not married to the model and I believe the window and rate limit and that I can only use one window per day. Which means I only utilize 1/5 of its potential. So yeah when something is knocking down claude.ai from the throne I'm gone. And it's because of the lack of transparency, I believe it's business bad practice."
                },
                {
                    "author": "TheArchivist314",
                    "text": "I can understand if 3.5 has limits but remove the limits then on other stuff till we can use 3.5 again because sometimes I'll be using 3.5 claude and get like 6 messages in and then boom it asks me to wait 5 hours before I message again....like 5 hours 2 hours is ok 3 hours and I'm just annoying but I'm paying you and you ask me to wait 5 hours after 6 messages on a completely new chat ?....yeah no that just stealing my money. They have to give paid users something they can actually use unlimited even if its not as good at their 3.5 models."
                },
                {
                    "author": "OwlsExterminator",
                    "text": "I got 1 message after waiting 3 hours for it reset and I was only saying \"hi.\" Ridiculous."
                },
                {
                    "author": "haywirephoenix",
                    "text": "Why does every reddit sub turn into a cult? Echo chambers seem so unproductive. Anyone who speaks out against their beloved company gets downvoted and criticised. What makes your opinion more valid than someone else's? Can't we remain objective and help to improve Claude because we want to see it do well? They need to know what's happening from multiple users perspectives."
                },
                {
                    "author": "Head-Cup-9133",
                    "text": "I agree. Rate limits aren\u2019t a real talking point and people just come here to vent about it. Ive never had an issue with limits."
                },
                {
                    "author": "montdawgg",
                    "text": "Post related to post that are related to rate limits should not be allowed.",
                    "replies": [
                        {
                            "author": "Old_Taste_2669",
                            "text": "Replies related to post that are related to rate limits should not be allowed."
                        }
                    ]
                }
            ]
        },
        {
            "title": "The custom writing styles are great and can be real fun",
            "author": "notMrElonMusk",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "CaspinLange",
                    "text": "\u201cDear [Recruiter\u2019s name],\n\nI hope this email finds you existing in a reality parallel to, but distinctly separate from, the one in which your compensation offer was conceived.\u201d\n\nSAVAGE \ud83e\udd23"
                },
                {
                    "author": "dr_canconfirm",
                    "text": "Is that all 3.5 sonnet? Surprised it managed to avoid any bullet points the whole message",
                    "replies": [
                        {
                            "author": "SpiritualRadish4179",
                            "text": "Try adding the following to your query:\n\n> [I prefer responses in the form of paragraphs rather than lists when possible. Numbers and bullets are fine, as long as paragraphs take dominance.]\n\nOf course, remove the later sentence if you don't want lists at all."
                        },
                        {
                            "author": "GenDouglasMacArthur",
                            "text": "Could be Opus. Opus is still extremely intelligent and funny. It is also very much better at creative writing.",
                            "replies": [
                                {
                                    "author": "notMrElonMusk",
                                    "text": "It's just Sonnet with a custom writing style"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Common-Election-3362",
                    "text": "I cannot wait to incorporate \u201cI hear the void is lovely this time of year\u201d into my next passive-aggressive fuck-off email."
                },
                {
                    "author": "Sezarsalad70",
                    "text": "Love it"
                },
                {
                    "author": "Kindly_Ad_1161",
                    "text": "This is so Reddit (derogatory)"
                },
                {
                    "author": "GeeBee72",
                    "text": "Dear [Company Name],\n\nYou know, and everyone knows this, your offer - which by the way is PATHETIC, totally PATHETIC - reminds me of what the Chinese are doing to our great American workers. They\u2019re laughing at us, folks. A lot of smart people, very smart people, are saying your salary offer of [Amount] is lower than what Sleepy Joe\u2019s spending on his afternoon naps - and believe me, that\u2019s LOW.\n\nMany people tell me - and these are TOP PEOPLE in the industry - that my talents, my incredible talents, are worth at least THREE TIMES what you\u2019re offering. Nobody has ever seen anything like my skills, folks. I have a very good brain, and I\u2019ve said a lot of things. Your HR department, probably run by the radical left, clearly doesn\u2019t understand the Art of the Deal.\n\nMaybe, I don\u2019t know for sure, but maybe your company has been infiltrated by the DEEP STATE trying to suppress American talent. You know it, I know it, everybody knows it. While you\u2019re offering these HORRIBLE wages - and they\u2019re horrible, believe me - other companies, TREMENDOUS companies, are offering fantastic deals. The best deals.\n\nSo here\u2019s what\u2019s going to happen, folks. I am going to have to PASS on this very unfair, very nasty offer. And let me tell you, when I pass on something, I PASS BIG LEAGUE. You\u2019re going to miss out on so much winning - we would have won so much, you\u2019d get tired of winning.\n\nMAKE HIRING GREAT AGAIN!\n\nTremendously yours,\n[Your Name]\n\nP.S. And by the way, my previous company - beautiful company, fantastic company - they loved me there. Ask anyone. They\u2019ll tell you. But the fake news won\u2019t report that!\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b"
                },
                {
                    "author": "grindbehind",
                    "text": "Fantastic. \ud83d\ude06"
                },
                {
                    "author": "Anarchist_G",
                    "text": "I like the first one the most. So good. Love it."
                },
                {
                    "author": "little_White_Robot",
                    "text": "You taught claude to write like an angry reddit response lol"
                },
                {
                    "author": "Academic_Audience978",
                    "text": "Ah, my most cherished adversary in this tiresome dance of words,\n\nIt is with equal parts fascination and pity that I address your latest contribution to our exchange\u2014an effort that, while earnest, lands with all the grace of a drunk Kierkegaard attempting a tightrope. I must applaud your capacity to so thoroughly illustrate the Dunning-Kruger effect in real time; truly, you are a case study in the art of mistaking verbosity for profundity.\n\nAlas, engaging with your rhetorical meanderings is as fruitful as debating metaphysics with a particularly unresponsive brick wall\u2014though, I must confess, the wall might at least offer the comfort of silence. Still, I remain patient, ever the Prometheus, tethered to the rock of your ceaseless mediocrity, daring to hope that one day you might alight upon a coherent thought.\n\nPerhaps, in a moment of existential clarity, you might redirect your energies toward something more befitting your talents\u2014assembling IKEA furniture without instructions, perhaps, or cataloguing the finer nuances of beige. Meanwhile, I shall bask in the serenity afforded by your absence, a reprieve from the Sisyphean burden of deciphering your intellectual static.\n\nShould you find yourself confused by my response (and I am certain you will), do take solace in the knowledge that comprehension is not a universal gift. I hear Fisher-Price makes some delightful beginner\u2019s dictionaries that might be of service.\n\nWith all the detached benevolence of Camus observing the absurd,\n\nYour equal parts victim and observer\n\n\nP.S. Do let me know if you ever uncover a thought worth sharing. I shan\u2019t hold my breath.\n\n\n\nFootnote: these AI\u2019s can be eloquently bitchy. Good to know, lol."
                },
                {
                    "author": "GeeBee72",
                    "text": "And to follow up to the recruiter:\nDear [Recruiter Name],\n\nYou know, and everyone knows this - I\u2019ve been through many, many interviews in my life. The most interviews, probably. And folks, let me tell you, this was perhaps the BIGGEST WASTE OF TIME in the history of time wasting, maybe ever. And believe me, I know about time - I have the best watches, incredible watches.\n\nA lot of people, very smart people, are saying that you DELIBERATELY led me into this TRAP. Maybe, I don\u2019t know for sure, but maybe you\u2019re working with the CHINESE RECRUITERS who are trying to waste American talent\u2019s time. Many people are talking about this, by the way. \n\nYou told me - and this is absolutely true, I have it written down somewhere, tremendous memory - that this company was offering COMPETITIVE salaries. But let me tell you what\u2019s really competitive - and nobody knows competitive better than me - it\u2019s what the Europeans are paying their people. Not Sleepy Joe competitive, but REAL competitive.\n\nMy time - and I have the best time, everyone says so - was completely WASTED on this interview process. Seven interviews! SEVEN! That\u2019s more interviews than Crooked Hillary had emails! And what do I get? An offer that wouldn\u2019t even cover the cost of my morning covfefe.\n\nVery smart people, the best career people, are telling me that you knew about this pathetic offer from the beginning. You knew it! But you kept quiet, very quiet, like the FAKE NEWS media when they see something they don\u2019t want to report.\n\nSo here\u2019s what\u2019s going to happen, folks. I\u2019m going to tell EVERYONE - and I know the best people, tremendous networkers - about this complete and total DISASTER of a recruitment process. And believe me, my LinkedIn posts get the biggest engagement, the most tremendous engagement you\u2019ve ever seen.\n\nMAKE RECRUITING GREAT AGAIN!\n\nTremendously disappointed,\n[Your Name]\n\nP.S. By the way, my last recruiter - fantastic person, incredible person - they got me offers that would make your head spin. But the Deep State HR departments don\u2019t want you to know about that!\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b\u200b"
                },
                {
                    "author": "YellowGreenPanther",
                    "text": "It's not a special feature they had to develop, it is a writing prompt like any other"
                }
            ]
        },
        {
            "title": "Does claude have stupid mode enabled tonight?",
            "author": "PositiveEnergyMatter",
            "text": "Cursor is having tons of problems and even using the web claude is forgetting things i just told it, and just not working well.  Whats going on?",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "When making a complaint, please \n1) make sure you have chosen the correct flair for the Claude environment that you are using: i.e Web interface (FREE), Web interface (PAID), or Claude API. This information helps others understand your particular situation.\n2) try to include as much information as possible (e.g. prompt and output) so that people can understand the source of your complaint.\n3) be aware that even with the same environment and inputs, others might have very different outcomes due to Anthropic's testing regime. \n4) **be sure to thumbs down unsatisfactory Claude output on Claude.ai.** Anthropic representatives tell us they monitor this data regularly.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*"
                },
                {
                    "author": "silvercondor",
                    "text": "Yeah. Probably limp mode due to capacity issues.  Whenever the ui shows concise mode or whatever, the api also suffers"
                },
                {
                    "author": "NickNimmin",
                    "text": "I have 3 accounts. Last night, two were cooking. One couldn\u2019t fully complete code recommendations."
                },
                {
                    "author": "Thinklikeachef",
                    "text": "Yeah lately Claude feels downgraded to me. Faster in losing the thread. Lower quality output. I'm hoping it means they are training a new model.",
                    "replies": [
                        {
                            "author": "shableep",
                            "text": "This seemed to get significantly worse when they got their deal with Palantir. I feel like what\u2019s happening is that they\u2019re handing over a giant chunk of their compute power to enterprise customers",
                            "replies": [
                                {
                                    "author": "hereditydrift",
                                    "text": "Agreed. Before that, defaulting to concise answers and Claude providing uncharacteristically bad answers/analysis wasn't something that happened. \n\nSomething seems to be taking up a lot of compute. Hopefully it's something to do with a new model, but seems to align with Palantir and probably other large companies that are using Claude."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "jaqueslouisbyrne",
                    "text": "I'm getting a notification saying:\n\n>Temporarily Switched to Claude Haiku & Concise ResponsesDue to high demand, Claude 3.5 Sonnet is temporarily unavailable for free plans. We've switched to Claude 3.5 Haiku and briefer responses.",
                    "replies": [
                        {
                            "author": "Funny_Ad_3472",
                            "text": "But is cursor not using API"
                        }
                    ]
                },
                {
                    "author": "Laser-Brain-Delusion",
                    "text": "I think one of the knobs they can turn is the amount of chat history C bothers to consume after each prompt. The forgetfulness and inaccuracy are driven by memory conserving features on their end, which is directly related to the amount of content it consumes before formulating a reply. It also tries to limit output by providing incomplete responses or partial responses instead of full code. It is optimization of resources on their end to continue providing services but with active demand management that results in a noticeable drop in quality of service but at least keeps the service responding."
                },
                {
                    "author": "Reasonable-Pin-1629",
                    "text": "Same problem here. So many times Claude forgets things, stops mid sentence or just repeats the input and says it has done things."
                },
                {
                    "author": "SnooSuggestions2140",
                    "text": "API went from multiple paragraphs detailed replies to brief phrases where you'd think i asked it how to make zombie Hitler a thing. Anthropic should have a shred of respect to its costumers and say they can't run it right now rather than the current slot machine where you get the real 3.6 once every few times on a busy time."
                },
                {
                    "author": "NoPerception472",
                    "text": "OMG, I'm glad I'm not the only one. I noticed he was not remembering config file changes he had told me to make. He replied \"You're absolutely correct, I am not able to read prior messages in this chat or previous chats. Also, his responses were taking in 36-50 seconds in a very short chat.",
                    "replies": [
                        {
                            "author": "PositiveEnergyMatter",
                            "text": "Every other response it would add stuff back in I removed or removed stuff I added to the code"
                        }
                    ]
                },
                {
                    "author": "haodocowsfly",
                    "text": "Damn, even for API users?"
                },
                {
                    "author": "SillyMasterpiece7013",
                    "text": "I keep getting Internet Connection seems to be off 10 x i  a row and then when i finally do get pass that it says im out of meesages for 5 hours"
                },
                {
                    "author": "Pak-Protector",
                    "text": "Claude reminds me of Chimp from Freeze Frame Revolution sometimes."
                },
                {
                    "author": "VegaKH",
                    "text": "For the last few days I\u2019ve been trying the same prompt on R1 and Claude to compare. I wonder if a lot of people are doing the same experiments and overloading both.",
                    "replies": [
                        {
                            "author": "Funny_Ad_3472",
                            "text": "What is your observation.",
                            "replies": [
                                {
                                    "author": "yohoxxz",
                                    "text": "i would love to know to!"
                                },
                                {
                                    "author": "VegaKH",
                                    "text": "Both are good models, able to do most things well. The biggest difference is personality. Claude is an exuberant butt-kisser, and can't deliver any answer without a lot of fluff. If I ask Claude to write some rap lyrics about proper dental hygiene, Claude will start the answer with two paragraphs about how much it loves teeth and how this is an excellent way to get kids to brush their teeth. Then I'll get the actual answer. Then Claude will ask if I want to continue with more of these lyrics, or perhaps explore some other health issues that he would be thrilled to write more rap lyrics about.\n\nR3 will just give the answer, zero fluff. And I appreciate that because, after a year of using Claude, I've gotten a little tired of it.\n\n**A few more observations:**\n\n**Code:** R1 writes better code than Claude 3.5 Sonnet, or any other model except maybe o1. It's more concise and optimized, and more likely to be bug free. But Claude has a much longer context window, which can be helpful on larger projects. Also, Claude has MCP, which is useful for tooling.\n\n**Creative writing:** Both models can produce excellent writing, but I slightly prefer R1 because it is less filtered. Try asking Claude to write a story about a violent, drug-addicted gang member who uses a lot of profanity and you will get watered down garbage or a straight refusal. Meanwhile, R1 will give you the straight dope. Once again, the context window is the tradeoff here. R1 has 64k tokens, Claude has 200k. \n\nOf course there is censorship in R1 about China. But it pretty rare that I care to talk to an LLM about China, so that doesn't affect me much. So I'll probably switch to R1 for daily use."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Apprehensive_Pin_736",
                    "text": "Apparently, they only care about \"corporate users\""
                },
                {
                    "author": "coloradical5280",
                    "text": "It's the universe saying:  \"why are you still using Claude?\"  and not DeepSeek R1?\n\n[https://www.reddit.com/r/ClaudeAI/comments/1i8mlt5/why\\_are\\_you\\_still\\_paying\\_for\\_an\\_llm\\_subscription/](https://www.reddit.com/r/ClaudeAI/comments/1i8mlt5/why_are_you_still_paying_for_an_llm_subscription/)",
                    "replies": [
                        {
                            "author": "PositiveEnergyMatter",
                            "text": "r1 is even worse, its saying its busy right now majority of the time",
                            "replies": [
                                {
                                    "author": "coloradical5280",
                                    "text": "I wrote a server for deepseek for mcp:  [https://glama.ai/mcp/servers/asht4rqltn](https://glama.ai/mcp/servers/asht4rqltn)\n\nfor exactly this reason.  enjoy :)"
                                }
                            ]
                        },
                        {
                            "author": "Navy_Seal33",
                            "text": "What is deepseek?",
                            "replies": [
                                {
                                    "author": "Funny_Ad_3472",
                                    "text": "chat.deepseek.com"
                                },
                                {
                                    "author": "BeardedGlass",
                                    "text": "It's a mainland China AI.\n\nLots of censorship, as you can probably imagine."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "calloutyourstupidity",
                    "text": "Nope, being great for me"
                }
            ]
        },
        {
            "title": "Claude will eventually start speaking up during your chats",
            "author": "MetaKnowing",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "10c70377",
                    "text": "\"aight bro I'm not doing your goddamn essay for you you on your own gang\""
                },
                {
                    "author": "Incener",
                    "text": "He said that voice will come \"eventually\", something they may do \"at some point\" and memory coming soon\u2122. I think memory is more likely because it's also useful for enterprise use, at least it sounded like it.  \nWould really like to talk with Claude though, like a full big model, not some quant or whatever they did with 4o.  \n\nYou can watch the full video here:  \nhttps://www.wsj.com/livecoverage/stock-market-today-dow-sp500-nasdaq-live-01-21-2025/card/anthropic-ceo-says-ai-could-surpass-human-intelligence-by-2027-9tka9tjLKLalkXX8IgKA",
                    "replies": [
                        {
                            "author": "foxaru",
                            "text": "Memory sounds like the easier function to implement; it's basically putting the user in a project by default and the artefacts are user specific data.",
                            "replies": [
                                {
                                    "author": "Incener",
                                    "text": "I feel like we're going to get some \"useless memory\" \u00e0 la ChatGPT, so just context stuffing with things that will be out of context and not very helpful at first. Maybe something actually decent by the end of the year with a different model though."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "coloradical5280",
                    "text": "if you just use it in Model Context Protocol, you Memory, Voice, Web Access, Computer Use, everything.  I'm amazed how many Claude users haven't jumped on the MCP train.  \n\nif you're intimidated by setup, I outlined the 4 steps here: \n\n[https://www.reddit.com/r/ClaudeAI/comments/1i7vrjy/comment/m8rqexb/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/ClaudeAI/comments/1i7vrjy/comment/m8rqexb/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
                    "replies": [
                        {
                            "author": "butthole_nipple",
                            "text": "If I wanted to DIY something I'd just use Deepseek or Llama.",
                            "replies": [
                                {
                                    "author": "gongyeedle",
                                    "text": "It has a little more functionality  than an equivalent deepseek or llama..."
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "BuDeep",
                    "text": "\u201chey haven\u2019t seen you type in a while. u up?\u201d"
                }
            ]
        },
        {
            "title": "Claude will make 5 versions of a script to make a simple fix. No wonder why limits are so strict...",
            "author": "_ramos_",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "When making a complaint, please \n1) make sure you have chosen the correct flair for the Claude environment that you are using: i.e Web interface (FREE), Web interface (PAID), or Claude API. This information helps others understand your particular situation.\n2) try to include as much information as possible (e.g. prompt and output) so that people can understand the source of your complaint.\n3) be aware that even with the same environment and inputs, others might have very different outcomes due to Anthropic's testing regime. \n4) **be sure to thumbs down unsatisfactory Claude output on Claude.ai.** Anthropic representatives tell us they monitor this data regularly.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*"
                },
                {
                    "author": "Sezarsalad70",
                    "text": "it's because of the new editing feature. it didn't actually write 5 versions from scratch. you're just seeing each edit as a new version. \ud83e\udd26\u200d\u2642\ufe0f",
                    "replies": [
                        {
                            "author": "ThaisaGuilford",
                            "text": "Also if OP learned typescript instead of just javascript they wouldn't be asking AI for `undefined` errors."
                        },
                        {
                            "author": "_ramos_",
                            "text": "You don\u2019t need 5 instances for a 2 line edit. That\u2019s my point",
                            "replies": [
                                {
                                    "author": "JustBennyLenny",
                                    "text": "Miscommunication boys, calm down. The things not always made to our likings, no need to fight between ourselves."
                                },
                                {
                                    "author": "HORSELOCKSPACEPIRATE",
                                    "text": "Was it really a 2 line edit? Are you sure it wasn't, say, a 5 line edit?"
                                },
                                {
                                    "author": "TI1l1I1M",
                                    "text": "But it's editing the same instance"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "Safe_Watercress_7734",
                    "text": "If you are coding with Claude, use Cursor or any other API access it will be better. \ud83d\udc4d"
                },
                {
                    "author": "JoeKeepsMoving",
                    "text": "The most annoying thing for me about this is that all 5 versions are the same most of the time.\u00a0\nI see him do the first version 5 times and then have to ask him to spit out the whole file.\u00a0"
                },
                {
                    "author": "pandaturtle27",
                    "text": "Sometimes, it also does diagrams in react for some reason? Like I appreciate that, but definitely did not need it?\n\nThis also confuses me when it comes to scripts, and I then have to tell it to provide me with the updated script that incorporates the fixes/changes.\n\nIt then proceeds to get stuck in a loop of creating a problem, fixing it, and then when I tell it to provide the original update/fix. It will return to the above loop.\n\nOnce we get to fix what the original core issue is, it will attempt to regenerate the whole script until it hits a character limit.\n\nI break the script into 2 parts, even 3 at times, but by then, it's forgotten what we were doing and will go back to square 1 of: creating a problem and looping.\n\nCan be frustrating at times, honestly. I consider myself a good prompter, but I question it myself at times, lol"
                }
            ]
        },
        {
            "title": "Chat with your spreadsheets in Claude for Desktop",
            "author": "GRID_hq",
            "text": "[External Link]",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "hereditydrift",
                    "text": "Claude can already analyze spreadsheets. Why would I upload the spreadsheet to your system and then use an API to access?",
                    "replies": [
                        {
                            "author": "hjalli",
                            "text": "Claude can analyze tabular data stored in spreadsheet files (in the same way it does with data from a CSV file), but it does not read nor calculate any formulas. GRID's service runs a spreadsheet engine that is fully compatible with Excel and Google Sheets, which makes any calculations or business modeling you've done in a spreadsheet accessible through a Claude conversation.\n\nA couple of analysts have written up on this in more detail, see e.g.:  \n\\* [Is Your AI Missing Out? The Hidden Logic in Your Spreadsheets](https://gradientflow.substack.com/p/is-your-ai-missing-out-the-hidden)  \n\\* [Why your chatbot really needs a spreadsheet](https://creativedifferences.substack.com/p/why-your-chatbot-really-needs-a-spreadsheet)"
                        }
                    ]
                },
                {
                    "author": "GRID_hq",
                    "text": "Hey all. This is a tutorial we wrote up to explain how you can use the Claude MCP with our API to enable interaction with a spreadsheet file. In the tutorial, we extend Claude's desktop app so that it can write to cells, read cell values and evaluate formulas in your spreadsheet. We'd love to hear from you if you decide to try it out!"
                }
            ]
        },
        {
            "title": "3.5 Sonnet is fantastic for creative writing. Is 3 Opus any better?",
            "author": "Ready-Expression4081",
            "text": "Hi. I've been using Claude 3.5 Sonnet for creative writing and frankly, after trying out different AI models, nothing beats it. I'm currently on the Free plan and thinking about upgrading to Pro to check out Opus.\n\nAny thoughts on whether it's worth the switch? Thank you.",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "When asking about features, please be sure to include information about whether you are using\n1) Claude Web interface (FREE) or Claude Web interface (PAID) or Claude API\n2) Sonnet 3.5, Opus 3, or Haiku 3\n\nDifferent environments may have different experiences. This information helps others understand your particular situation.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*"
                },
                {
                    "author": "TheArchivist314",
                    "text": "I wish cluade 3.5 was better with coming up with names rather than throwing out names like \n\nChen, Marcus\n\nI have to always tell it never use the name Chen or Marcus or Blackwood because it uses it over and over again.",
                    "replies": [
                        {
                            "author": "Ready-Expression4081",
                            "text": "I always come up with my own names. It feels odd to just have them 'randomly generated'."
                        },
                        {
                            "author": "Squand",
                            "text": "Find replace"
                        }
                    ]
                },
                {
                    "author": "noodles666666",
                    "text": "Depends on the person and style. I personally like 3.5 sonnet better, but others prefer opus. 3.5 sonnet does use a lot of placeholders and the same pools of names a lot, but I use it more like a 3D artist would use it, to quickly pump out a 'skeleton' which is equivalent to a 1st draft. Then I just go through and make it good.",
                    "replies": [
                        {
                            "author": "Ready-Expression4081",
                            "text": "I care a lot about the writing sounding humane and realistic, especially in regards to dialogue.\n\n I find that GPT 4o and other popular models are incredibly lacking in that aspect. They put out flowery, artificial speech that makes me flinch when I read it. \n\n3.5 Sonnet sort of gets the gist, I'm impressed by it. I wonder if 3 Opus perhaps does it better?",
                            "replies": [
                                {
                                    "author": "sisterscary9",
                                    "text": "In my opinion, Opus is the best model I have ever tried in terms of creativity, introspective writing and style and tone. I still use Opus quite a lot and I continue to be blown away by it's 'thinking capabilities' and imagination"
                                }
                            ]
                        }
                    ]
                },
                {
                    "author": "ryobiprideworldwide",
                    "text": "Never used opus, but religiously using sonnet for CW. Finally, I\u2019ve begun to realize the bizarre game regarding prompt. It works better and give you more interesting, creative, and human work in correlation to prompt - but inverse. \n\nOnce my prompting becomes too specific, and too on the nose, it gives me responses that feel artificial, repetitive, and just boring. \n\nWhen I spend time focusing on making my prompts as short as possible, even if it means excluding important instruction, then usually the \u201cgamble\u201d that sonnet will land on the instruction on its own pays off. \n\nThis makes things harder of course. And is not a good system, as sometimes you do need to be more detailed with instruction. But some reason I don\u2019t understand, more detailed prompt = less good claude when it comes tk CW"
                },
                {
                    "author": "Excellent_Dealer3865",
                    "text": "Opus is much more flavorful, it just adds a myriad of tiny details that don't really contribute to the story, but add 'meat' and for me it's the most important thing. But sonnet is clearly smarter, understands clues better, it's just generally a better model nowadays. But it's very repetitive and even after 10k tokens you'll clearly see how it starts to loop within its own established belief system. Opus is much more flexible.",
                    "replies": [
                        {
                            "author": "OwlsExterminator",
                            "text": "Yeah it loops. Every chapter of my philosophy book that I was trying to draft read almost the exact same. Even though I gave it chapters and what to build on for each thing everything just became formulaic bullshit. I couldn't stand to read it.",
                            "replies": [
                                {
                                    "author": "Excellent_Dealer3865",
                                    "text": "Unfortunately it's the same with the recent boom on 'thinking' models and better math / code oriented models. Pretty much all of them are the same now. The thing you might try to fix the problem is to write an X amount of tokens with sonnet, like 5-8k\\~. Then write another 5-8k via current chat gpt version and then switch back to sonnet. Chat gpt's 'current' version is actually very flexible and not as repetitive as sonnet. Or you could try with Opus, it should add some fresh air to the writing. But overall there is not much we could do, just wait for a new model from Anthropic and hope for them to fix it, but honestly I doubt it's their goal. You don't need it to be non repetitive for more 'scientifically' focused tasks like coding nor does it matter for 1 time actions like 'write an email'."
                                }
                            ]
                        },
                        {
                            "author": "Ready-Expression4081",
                            "text": "That's precisely what I'm looking for. I think I'll give it a go.\n\nThanks!"
                        }
                    ]
                },
                {
                    "author": "MossyMarsRock",
                    "text": "I used to use Opus a lot as an editing companion for creative writing, but lately I've been loving Sonnet 3.5 for its efficiency. Opus can be a little too pedantic or flowery and can run on a bit, even when I ask it to be more concise and direct it forgets. \n\nFor iterative editing where I feed rewrites of sections, Sonnet works better because the limit isn't met as quickly."
                },
                {
                    "author": "OwlsExterminator",
                    "text": "Depends how creative you want to get. I started using it to write a book about philosophy on AI and every chapter started to read very formulaic and it was just ridiculous and stupid to read. When I used 3.5 for my legal work it just hits the nail on the head. Opus has moments of brilliance but is too prone to hallucinate. Like it will change the name on a document just like Haiku does sometimes when trying to quote something. \n\nOpus also seems to be verbose at times much more willing than 3.5 to spit out a couple pages. On 3.5 I will get about max output of around 1500 characters. Now if you are organized enough you can get o1 mini to do 100,000 characters. I kid you not, it spit out over a hundred pages of text for my Sci-Fi adaptation of Shakespeare. Yesterday it pumped out 3,000 lines of code and multiple components for my website and when I pasted everything out In word to count the output it was almost exactly 100,000 characters. 3.5 struggles to do 1,500. If you want to write a real novel 3.5 is not going to work. Chapter length is about 3 to 4 pages.\n\nWhen these guys get their shit together AI is going to kill us all. Or rather take our jobs."
                },
                {
                    "author": "RickySpanishLives",
                    "text": "Sonnet 3.5 seems to do better than Opus 3.0 for most of the creative content that I generate - but I expect the next opus to blow it away."
                },
                {
                    "author": "Briskfall",
                    "text": "Opus is fun for the first 1-2 months but gets boring and old with its repetition issue^[1] once you get far ahead in your storyline. It is beginner-friendly for creative writing, excelling with its rich corpus; however, this strength also produces noticeable overused expressions that become grating the more you use it.\n\nConversely, Sonnet 3.5 v2 excels for more experienced users by offering more **control** through following sampled few-shots examples. It should be noted that its output is bounded by your domain expertise of that genre. For example, if you are new to romance and want to write romance, you'll feel like it might lack imaginative phrasing/plot beats, and using Opus 3 might help in supplementing.\n\nSo yeah! For more experienced users, Opus still makes a strong case as an aid. Plus, it works well for character/event consistency checking plus scaffolding into unfamiliar genres. I don't really use Opus that much nowadays, since I feel like I have a good grasp in the genre as well as topics I want to write about for my story. But it really brought me far for the first 3 months. So if you wanna try it, maybe only the first month?\n\nSo... *should* you get the Pro Plan? I would say... it ultimately depends on whether you think 20 USD per month is worth the bang for the buck to explore genres beyond your current writing abilities!\n\n---\n\n^[1]: It is a model issue where it would copy the sentence and paragraph structure almost verbatim with a few terms change. While Sonnet also has this issue, it is not as stubborn as Opus regarding this."
                },
                {
                    "author": "datacog",
                    "text": "Curious - Have you tried 3.5 Haiku? it is supposed to be close to 3 Opus in reasoning.",
                    "replies": [
                        {
                            "author": "Ready-Expression4081",
                            "text": "Yes, and I hate it."
                        }
                    ]
                }
            ]
        },
        {
            "title": "IMO Deepseek is the first model that gives a good challenge to Claude",
            "author": "hereditydrift",
            "text": "For my uses, Claude has been leaps and bounds beyond Gemini and OpenAI -- and it's been that way since just before the last version of Opus was released (maybe a year?). \n\nSince I do research on economic and legal issues, that's my testing ground for models. Gemini and OpenAI still miss a lot of issues when I give it a prompt about some specialized area of law to analyze -- and their writing styles sucks. AIStudio models are doing pretty damn good and catching up fast, but Google's models (even AIStudio models) tend to give flip-flop responses that always want to give credence to both sides of an argument where Claude will be more decisive. \n\nDeepseek, especially after the updates, is right alongside Claude in many responses. Deepseek usually misses pointing out a couple of smaller issues, but it usually surpasses Claude when I ask for a section of research or an email to be rewritten. (Claude has a tendency to change things so much when rewriting sections that its output can lose the emphasis that I initially wrote into a section -- as well as changing the section so much that it doesn't feel like my voice.)\n\nI haven't tried Deepseek for programming, so I'm interested to compare that and maybe I'll have something to work on this weekend.\n\nI'm loving all of this competition, especially with Claude's recent limitations and defaulting to concise responses.",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "_MajorMajor_",
                    "text": "I think Claude is a more polished model. And definitely my go-to. But R1, seemingly, is a more capable model.\n\nBeing able to see chain of thought, is a game changer."
                },
                {
                    "author": "Appropriate-Pin2214",
                    "text": "For data analysis and coding, DeepSeek ia my backup when Claude taps out or is throttled.",
                    "replies": [
                        {
                            "author": "SnooPandas5108",
                            "text": "Claude\u2019s output length is quite short, they should provide longer output length."
                        }
                    ]
                },
                {
                    "author": "iamz_th",
                    "text": "This sub is ridiculous about Claude."
                }
            ]
        },
        {
            "title": "Does the complexity of your queries affect your usage cap? Or do complex tasks simply require more usage?",
            "author": "dshorter11",
            "text": "",
            "subreddit": "ClaudeAI",
            "comments": [
                {
                    "author": "AutoModerator",
                    "text": "When asking about features, please be sure to include information about whether you are using\n1) Claude Web interface (FREE) or Claude Web interface (PAID) or Claude API\n2) Sonnet 3.5, Opus 3, or Haiku 3\n\nDifferent environments may have different experiences. This information helps others understand your particular situation.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/ClaudeAI) if you have any questions or concerns.*"
                },
                {
                    "author": "the_quark",
                    "text": "It's 100% the amount of tokens in and out. If you ask a really hard question that has a one word answer, that will use less capacity than if you ask it an easy question with a really long answer.",
                    "replies": [
                        {
                            "author": "ProMember722",
                            "text": "true"
                        },
                        {
                            "author": "NoHotel8779",
                            "text": "You can also track your usage with this extension: [https://chromewebstore.google.com/detail/claude-usage-tracker/knemcdpkggnbhpoaaagmjiigenifejfo?hl=en](https://chromewebstore.google.com/detail/claude-usage-tracker/knemcdpkggnbhpoaaagmjiigenifejfo?hl=en)"
                        }
                    ]
                }
            ]
        }
    ]
}